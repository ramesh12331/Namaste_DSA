# â±ï¸ Time & Space Complexity â€“ Big O Notation (Beginner Friendly)

This README is designed as **Canva-ready notes** and **interview revision material**.
It explains **Time Complexity**, **Space Complexity**, and **Big-O notation** from scratch with examples.

---

## ğŸ“˜ What is Time Complexity?

**Time Complexity** measures how the **running time of an algorithm grows** as the input size `n` increases.

### Important Points â­

* Focuses on **number of operations**, not real clock time
* Machine, language, or hardware do NOT matter
* Measured using **Big-O notation**
* Describes **growth rate**, not exact time

---

## ğŸ§  What is Big-O Notation?

**Big-O notation** represents the **worst-case time or space usage** of an algorithm.

### Key Rules (Interview Gold â­)

* Always consider the **worst case**
* Ignore constants â†’ `O(2n)` becomes `O(n)`
* Ignore smaller terms â†’ `O(nÂ² + n)` becomes `O(nÂ²)`
* Focus only on the **dominant factor**

---

## ğŸ” Example 1: Linear Search (Very Detailed for Beginners)

### ğŸ§  What is happening?

We check **each element one by one** until we find the target.

Think of it like:

> Searching a name in an unsorted notebook, page by page.

---

### JavaScript Code (With Line-by-Line Explanation)

```js
function linearSearch(arr, target) {
  // Loop through each element
  for (let i = 0; i < arr.length; i++) {

    // Compare current element with target
    if (arr[i] === target) {
      return i; // Stop immediately if found
    }
  }

  // If loop finishes, element not found
  return -1;
}
```

---

### ğŸ§ª Dry Run Example

Array: `[2, 1, 3, 5, 4, 7]`
Target: `5`

| Step | i | arr[i] | Comparison | Result       |
| ---- | - | ------ | ---------- | ------------ |
| 1    | 0 | 2      | 2 == 5 âŒ   | continue     |
| 2    | 1 | 1      | 1 == 5 âŒ   | continue     |
| 3    | 2 | 3      | 3 == 5 âŒ   | continue     |
| 4    | 3 | 5      | 5 == 5 âœ…   | found â†’ stop |

---

### â± Time Complexity Explained

* Best Case: element at index 0 â†’ **1 step â†’ O(1)**
* Worst Case: element at end / absent â†’ **n steps â†’ O(n)**

â¡ If array size doubles, work doubles.

---|------------|
| 10 | 10 |
| 100 | 100 |
| 1000 | 1000 |

â¡ Growth is **linear**

---

## ğŸ” Example 2: Binary Search (Very Detailed for Beginners)

### ğŸ§  What is happening?

We **cut the array into half** again and again.

Think of it like:

> Finding a word in a dictionary by opening the middle page.

âš ï¸ Works only on **sorted arrays**.

---

### JavaScript Code (With Explanation)

```js
function binarySearch(arr, target) {
  let left = 0;
  let right = arr.length - 1;

  while (left <= right) {
    let mid = Math.floor((left + right) / 2);

    if (arr[mid] === target) {
      return mid; // Found
    }
    else if (arr[mid] < target) {
      left = mid + 1; // Search right half
    }
    else {
      right = mid - 1; // Search left half
    }
  }
  return -1;
}
```

---

### ğŸ§ª Dry Run Example

Array: `[1, 3, 4, 7, 9, 10, 15]`
Target: `15`

| Step | left | right | mid | arr[mid] | Action   |
| ---- | ---- | ----- | --- | -------- | -------- |
| 1    | 0    | 6     | 3   | 7        | go right |
| 2    | 4    | 6     | 5   | 10       | go right |
| 3    | 6    | 6     | 6   | 15       | found    |

---

### â± Time Complexity Explained

Each step halves the problem:

```
n â†’ n/2 â†’ n/4 â†’ n/8 â†’ 1
```

So number of steps = **logâ‚‚ n**

â¡ Even for very large `n`, steps grow slowly.

---|-------|
| 10 | ~3 |
| 100 | ~7 |
| 1000 | ~10 |

â¡ Growth is **logarithmic**

---

## ğŸ“ˆ Common Time Complexities (With Intuition)

| Complexity   | Meaning        | Example               |
| ------------ | -------------- | --------------------- |
| `O(1)`       | Constant       | Access array element  |
| `O(log n)`   | Halves input   | Binary Search         |
| `O(n)`       | Linear         | Linear Search         |
| `O(n log n)` | Divide + merge | Merge Sort            |
| `O(nÂ²)`      | Nested loops   | Matrix traversal      |
| `O(2â¿)`      | Exponential    | Brute-force recursion |

### Efficiency Order (Best â†’ Worst)

```
O(1) > O(log n) > O(n) > O(n log n) > O(nÂ²) > O(2â¿) > O(n!)
```

---

## ğŸ’¾ What is Space Complexity? (Beginner Friendly)

### ğŸ§  Simple Meaning

Space Complexity = **extra memory** used by an algorithm.

We do NOT count:

* Input array itself

We DO count:

* New variables
* New arrays
* Function call stack

---

### ğŸ” Example: Finding Maximum (No Extra Space)

```js
function findMax(arr) {
  let max = arr[0];
  for (let i = 1; i < arr.length; i++) {
    if (arr[i] > max) max = arr[i];
  }
  return max;
}
```

* Variables used: `i`, `max`
* Do they grow with n? âŒ

âœ… Space = `O(1)`
âœ… Time = `O(n)`

---

### ğŸ” Example: Creating New Array (Extra Space)

```js
function doubleArray(arr) {
  let newArr = [];
  for (let i = 0; i < arr.length; i++) {
    newArr.push(arr[i] * 2);
  }
  return newArr;
}
```

* New array of size `n`

âœ… Space = `O(n)`

---

## ğŸ§  Space Complexity Rules â­

| What You Create        | Space   |
| ---------------------- | ------- |
| Variables (`i`, `max`) | `O(1)`  |
| Array of size `n`      | `O(n)`  |
| 2D matrix `nÃ—n`        | `O(nÂ²)` |
| Recursion depth `n`    | `O(n)`  |

---

## ğŸ” Space Complexity Examples

### Example 1: Constant Space

```js
function getElement(arr) {
  return arr[4];
}
```

* Space: `O(1)`
* Time: `O(1)`

---

### Example 2: Extra Array

```js
function doubleArray(arr) {
  let newArr = [];
  for (let i = 0; i < arr.length; i++) {
    newArr[i] = arr[i] * 2;
  }
  return newArr;
}
```

* Space: `O(n)`
* Time: `O(n)`

---

## âš ï¸ Time vs Space (Donâ€™t Confuse)

### Nested Loops

```js
for (let i = 0; i < n; i++) {
  for (let j = 0; j < n; j++) {}
}
```

* Time: `O(nÂ²)`
* Space: `O(1)`

### Independent Loops

```js
for (let i = 0; i < n; i++) {}
for (let j = 0; j < n; j++) {}
```

* Time: `O(2n)` â†’ `O(n)`
* Space: `O(1)`

---

## ğŸ§® Simplifying Big-O Expressions

| Expression        | Final Big-O |
| ----------------- | ----------- |
| `O(3n)`           | `O(n)`      |
| `O(nÂ² + n)`       | `O(nÂ²)`     |
| `O(nÂ³ + nÂ² + n)`  | `O(nÂ³)`     |
| `O(nÂ² + n log n)` | `O(nÂ²)`     |

---

## ğŸ§  Key Takeaways (Interview Gold âœ¨)

* Big-O describes **worst-case behavior**
* Ignore constants and smaller terms
* Binary Search â‰« Linear Search
* Loops affect **time**, not space
* Creating new arrays increases space

---

## ğŸ§¾ Final Summary

* **Time Complexity** â†’ how fast algorithm grows
* **Space Complexity** â†’ how much extra memory is used
* Big-O focuses on scalability
* Prefer `O(log n)` and `O(n log n)`
* Avoid `O(nÂ²)` and above when possible

---

ğŸš€ **These concepts are the backbone of DSA and interviews. Master them well.**
